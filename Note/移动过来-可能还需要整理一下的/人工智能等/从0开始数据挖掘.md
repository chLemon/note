# Part 1 赛题理解
1. 赛题
回归问题
给了哪些特征
和时间有没有关系，时间跨度有多大？
漂移？误报？异常值？
2. 赛制
3. 数据
显式特征（onehot编码 独立热编码
匿名特征（运算生成一些新的

数据范围，判断正常异常
数据样本有多大

理解评测标准

结果提交
注意格式，列名

常见评价指标：
分类：
二分类：acc，precision，recall，F-score，Pr曲线，ROC-AUC曲线
多分类：acc，宏平均和微平均，F-score
回归：
MAE，MSE，MAPE，R2

xgb，lgb，catboost

指标：sklearn.metrics

赛题理解究竟是理解什么：
什么样的问题
有了赛题理解后能做什么：
数据读取，看分布
赛题背景中可能潜在隐藏的条件
缺失，漂移，异常，背后的逻辑


Baseline

## 了解赛题类型
是回归、分类、还是其他

赛题背景可能会潜在一些隐藏条件，对之后的数据处理可能会有帮助
如是否包含异常值，缺失、漂移
是否会包含多种情况，这时需要注意模型的泛华性
高效性，比如工序流程的差异性，比如模型运行的时间、模型的鲁棒性
## 数据理解
### 字段含义
明确的特征：分类、连续、变量间的交互
匿名特征：四则运算、取log、统计指标
### 数据量
观察数据量以了解需要电脑配置的情况
### 评测标准
回归常用标准：MAE、MSE、R^2
线下验证的时候模型评价指标和线上保持统一
不同指标带来的差异效果是不一样的
### 结果提交
关注细节，是否需要列名等等
## 分析赛题
### 经验
数据比赛一般常用的模型：XGB，LGBM
sklearn是入门数据比赛一个很好的包，可以重点学习
### 回归问题
数据分析，特征的构建
选用好的模型
### 代码分析
用pandas读取数据
各类指标可以用sklearn，metrics包去构建
## baseline讲解
### 大佬的比赛流程
1. 先写一个baseline调教
2. 在baseline的基础上做优化：数据处理、特征处理、模型调参
3. 模型融合
### 读取数据、数据统计信息
info(),head()
describe()统计信息
对比train和test的情况：是否统计信息相近，详尽说明分布一致，模型效果稳定，如果分布不一致的话，需要对train做一些采样等处理，使两者分布接近
### 特征的类型
数值型、分类型
### 标签的分布
原理上来说，train和test的概率分布应该是一致的
### 模型构建
1. XGB LGB函数
2. param_grid网格调参
3. 切分数据集：train：validation = 7:3    4:1
4. 对比不同模型的结果解读：
  1. 对比均值 方差
  2. 将预测结果和train data对比，是否统计指标接近，是否有特殊的点需要关注处理
  3. 结合实际含义，比如最小值是负数
5. 不同模型的结果加权

# Part 2 EDA
探索性数据分析EDA

1. 数据大致表达了什么
2. 挖掘数据结构
3. 初步分离出一些重要特征
4. 挖掘离群数据和异常数据
5. 初步确定可以用哪些模型






## EDA要做什么
+ 数据大致表达了什么
+ 挖掘数据结构：结构化、图像等
+ 初步分离出一些重要特征
+ 挖掘离群数据和异常数据
+ 初步确定可以用哪些模型
## 绘图方法
1. 时序图，看看有没有缺失点
2. 统计图
3. 把特征一起画出来看



+ 时序图：变化规律：周期性等
+ 直方图：观察数据分布
+ 密度曲线：概率密度函数
+ 箱型图：查看数据异常状况。不同数据间分布的对比
+ 小提琴图：进阶版箱型图。某个值附近的概率分布
## 量化方法

统计一些特征表述

看一下取值范围

大概分布

### 相关性分析
+ 定类变量：性别
+ 定序变量：分类，且可排序，但差没有意义。教育程度
+ 定距变量：可比较大小，差值有意义，价格

|      | 定类       | 定序                              | 定距             |
| ---- | ---------- | --------------------------------- | ---------------- |
| 定类 | 卡方类测量 | 卡方类测量                        | Eta系数          |
| 定序 |            | Spearman相关系数、同序-异序对测量 | Spearman相关系数 |
| 定距 |            |                                   | Pearson相关系数  |

### 独立性分析
变量间无线性相关性，还可能存在非线性关联
MV test独立性检验



## Q&A

大部分模型都有基本假设：

1. 每个样本间独立同分布
2. 变量间相互独立
3. 不同模型有不同要求



很多模型假设自变量和因变量同分布，这时候就把标签正态分布一下



特征工程：

现在很多模型的发展，会让特征工程的工作越来越少，例如神经网络会自动提取特征，而线性回归就需要对量纲进行统一，归一化



版本迭代很重要！

# Part 3 特征工程

将数据转换为更好地表示潜在问题的特征，从而提高机器学习性能。

## 数据理解

目的：探索数据，了解数据，EDA

定型数据：定类，定序

定量数据：定距，定比（前者加减，后者乘除，不互斥



## 数据清洗

提高数据质量，最重要

1. 特征变换：模型无法处理或不适合处理

   a）定性变量编码

   逻辑斯特回归是不适合处理类别变量的，所以要把类别变量进行编码：Label Encoder; Onehot Encoder; Distribution Encoder

   b）标准化和归一化

   z分数标准化（标准正态）、min-max归一化

2. 缺失值处理：减少不确定性

   a）不处理，少量样本缺失

   b）删除，大量样本确实

   c）补全：（同类）均值/中位数/众数

   高维映射（one-hot）

   模型预测

   最邻近补全

   矩阵补全（R-SVD）

3. 异常值处理：减少脏数据

   a. 简单统计，散点图，describe()等

   b. 3σ法则（正态分布）/箱型图删除、截断

   c. 利用模型进行离群点检测，聚类、K近邻、One Class SVM、Isolation Forest

4. 其他：删除无效列/更改dtypes/删除列中的字符串/将时间戳从字符串转为日期格式 等等
## 特征构造
增强数据表达，添加先验知识
1. 统计量特征

   计数、求和、比例、标准差

2. 时间特征

   绝对时间、相对时间、节假日、双休日

3. 地理信息

   分桶

4. 非线性变换

   取log/平方/根号

5. 数据分桶

   等频/等距分桶、Best-KS分桶、卡方分桶

6. 特征组合/特征交叉  
## 特征选择

平衡预测能力和计算复杂度，降低噪声，增强模型预测性能

1. 过滤式Filter

   先特征选择，再让模型去学习

   Relief/方差选择/相关系数/卡方检验/互信息法

2. 包裹式Wrapper

   把最终的学习器的性能作为衡量特征子集的评价标准

   LVM

3. 嵌入式Embedding

   上两者的结合，将特征选择和学习器训练过程融为一体

   LR+L1或决策树
## 类别不平衡
1. 扩充数据集
2. 尝试其他指标、AUC等
3. 调整θ值：逻辑斯特回归
4. 重采样：过采样/欠采样
5. 合成样本：SMOTE
6. 选择其他模型：决策树
7. 加权少类别样本错分代价
8. 创新：

   大类分解，转为多分类问题

   小类视为异常点，用异常检测建模

# Part 4 建模和调参
## 基础知识
### 统计学习分类
1. 监督学习
2. 非监督学习
3. 半监督学习
4. 强化学习
### 常见的监督学习模型
1. 线性模型
2. 决策树
3. 神经网络
4. 支持向量机
5. 贝叶斯分类
6. 集成学习模型
### 基本概念
模型、策略与算法
评价函数
目标函数
过拟合与欠拟合
正则化
交叉验证
泛化能力
### 验证方法
训练集、线下验证集、线下测试集、线上测试集
无时序的数据集：简单划分、交叉验证划分等
有时序的数据集：需考虑时序，nested交叉验证划分等
### 注意
模型选择
依据在验证集上的效果选择
除了关注效果的均值，还要关注稳健性
还需考虑线上效果；可将线上效果视为一折数据

参数调优
不建议将精力放在参数调优上；容易过拟合
大体的设置参数即可
应将精力重点放在特征工程；其次是模型融合
